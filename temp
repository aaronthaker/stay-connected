import pandas as pd
import glob
import os
import chardet
from datetime import datetime, timedelta

script_dir = os.path.dirname(os.path.abspath(__file__))
data_dir = os.path.join(os.path.dirname(script_dir), 'Data')
output_dir = os.path.dirname(script_dir)

def find_latest_file(pattern):
    search_pattern = os.path.join(data_dir, pattern)
    files = glob.glob(search_pattern)
    if not files:
        print(f'Error: No files found matching {pattern} in {data_dir}')
        exit()
    return max(files, key=os.path.getctime)

def extract_date_from_filename(filename):
    base = os.path.basename(filename)
    try:
        date_str = base[10:20].replace('_','-')
        date = datetime.strptime(date_str, '%d-%m-%Y')
        return date
    except (IndexError, ValueError):
        print('Error: Unable to extract date from Report#28 filename.')
        exit()

report_file = find_latest_file('Report#28*.csv')
report_date = extract_date_from_filename(report_file)
week_end_date = report_date - timedelta(days=1)
week_start_date = week_end_date - timedelta(days=6)

# Convert date range to strings
date_range_start_str = week_start_date.strftime("%d-%m-%Y")
date_range_end_str = week_end_date.strftime("%d-%m-%Y")

hr_file = find_latest_file('hr_data_HRIdentities*.csv')

with open(hr_file, 'rb') as f:
    result = chardet.detect(f.read())
    hr_encoding = result['encoding']
    print(f'Detected encoding for HR file: {hr_encoding}')

hr_data = pd.read_csv(hr_file, encoding=hr_encoding)
required_columns_hr = ['DISPLAY_NAME', 'COUNTRY', 'MONITORED_STATUS']
if not all(col in hr_data.columns for col in required_columns_hr):
    print('Error: Required columns missing in hr_data_HRIdentities CSV.')
    exit()

hr_data = hr_data[required_columns_hr]

with open(report_file, 'r', encoding='utf-8-sig') as f:
    first_line = f.readline()
    if 'sep=,' in first_line:
        skiprows = [0]
    else:
        skiprows = []

report_data = pd.read_csv(report_file, skiprows=skiprows)

# Remove 'Typename ' prefix from column names
report_data.columns = [col.replace('Typename ', '') for col in report_data.columns]

if 'ME Name' not in report_data.columns:
    print('Error: "ME Name" column missing in Report#28 CSV.')
    exit()

merged_data = pd.merge(report_data, hr_data, left_on='ME Name', right_on='DISPLAY_NAME', how='left')
merged_data['MONITORED_STATUS'] = merged_data['MONITORED_STATUS'].astype(str).str.lower()
in_scope_data = merged_data[merged_data['MONITORED_STATUS'] == 'in-scope']
comm_start_idx = report_data.columns.get_loc('Generated Content')
comm_columns = report_data.columns[comm_start_idx:]

grouped_data = in_scope_data.groupby('COUNTRY')[comm_columns].sum().reset_index()

# Add the date range start and end to the dataframe
grouped_data['Date Range Start'] = date_range_start_str
grouped_data['Date Range End'] = date_range_end_str

# Reorder columns to have 'Date Range Start', 'Date Range End', 'COUNTRY', then comm_columns
cols = ['Date Range Start', 'Date Range End', 'COUNTRY'] + list(comm_columns)
grouped_data = grouped_data[cols]

output_file = os.path.join(output_dir, 'communication_counts_by_territory.xlsx')

if os.path.exists(output_file):
    existing_data = pd.read_excel(output_file)
    separator = pd.DataFrame([[''] * len(grouped_data.columns)], columns=grouped_data.columns)
    combined_data = pd.concat([existing_data, separator, grouped_data], ignore_index=True)
else:
    combined_data = grouped_data

with pd.ExcelWriter(output_file, engine='openpyxl', mode='w') as writer:
    combined_data.to_excel(writer, index=False)

print(f'Communication counts for {date_range_start_str} to {date_range_end_str} have been appended to {output_file}')