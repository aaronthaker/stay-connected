import time
import requests
import pandas as pd
import scipy.stats as st
from math import ceil
from datetime import datetime
import re

# API credentials
API_TOKEN = 'z6XeAVcCz0vsv-GHX_r-SOWRZmPfIhKD0XEQFSEe-Ds'
SSL_CERT_PATH = "./glencore.behavox-saas.crt"  # Ensure correct certificate is available

API_LIMIT = 2000  # Max number of communications per request

def sample_size(N: int, C: float, E: float, p: float = 0.5, round: bool = True) -> int:
    """Calculate sample size based on confidence interval and margin of error."""
    if N == 0:
        return 0
    Z = st.norm.ppf(1 - (1 - C) / 2)
    size = Z**2 * N * p * (1 - p) / (E**2 * (N - 1) + Z**2 * p * (1 - p))
    return ceil(size) if round else size

def get_comms_by_date(session, start_date: str, end_date: str, comms_per_page: int = API_LIMIT) -> pd.DataFrame:
    """Retrieve all communications within a given date range, handling pagination correctly."""
    if comms_per_page > API_LIMIT:
        raise ValueError(f"Comms per page must be less than {API_LIMIT}")

    base_url = f"https://glencore.behavox-saas.com/dashboard/api/3/communications/find"
    params = {
        "start-date": start_date,
        "end-date": end_date,
        "field": "alertIds",
        "limit": comms_per_page
    }

    comms = []
    cursor = None
    page = 0

    while True:
        if cursor:
            params["cursor"] = cursor  # Update cursor for pagination
        response = session.get(base_url, headers={"Authorization": f"Bearer {API_TOKEN}"}, params=params, verify=SSL_CERT_PATH)
        
        if response.status_code != requests.codes.ok:
            print(f"Error: Received {response.status_code} - {response.text}")
            response.raise_for_status()

        data = response.json()
        new_comms = data.get('communications', [])
        comms.extend(new_comms)
        
        if new_comms:
            last_id = new_comms[-1]['id']
            first_id = new_comms[0]['id']
            print(f"Page {page}: Retrieved {len(new_comms)} communications.")
            print(f"  - First comm ID: {first_id}")
            print(f"  - Last comm ID: {last_id}")

        cursor = data.get('pagination', {}).get('cursor')

        if not cursor:
            print(f"Pagination ended at page {page}. Retrieved {len(comms)} total communications.")
            break
        
        print(f"  - Next cursor: {cursor}\n")
        page += 1
        time.sleep(1)  # Avoid hitting API limits

    return pd.json_normalize(comms)

def get_comms_by_id(session, c_id: str) -> dict:
    """Retrieve detailed communication data by ID."""
    url = f"https://glencore.behavox-saas.com/dashboard/api/3/communications"
    params = {"ids": c_id}

    response = session.get(url, headers={"Authorization": f"Bearer {API_TOKEN}"}, params=params, verify=SSL_CERT_PATH)
    
    if response.status_code != requests.codes.ok:
        print(f"Failed to retrieve comm ID {c_id}: {response.text}")
        response.raise_for_status()

    return response.json()[0]  # Return the first (and only) communication object

def main(save_file: bool = False):
    start_date = "2025-01-06T00:00:00.000Z"
    end_date = "2025-01-06T11:59:59.999Z"

    with requests.Session() as session:
        # Get all comms within the period
        df_all_comms = get_comms_by_date(session, start_date, end_date)

        # Filter out communications with alert IDs (keeping only unalerted ones)
        df_unalerted_comms = df_all_comms[df_all_comms['alertIds'].apply(len) == 0]
        
        # Calculate the required sample size
        size = sample_size(N=len(df_unalerted_comms), C=0.9, E=0.05)
        print(f"Sampling {size} communications from {len(df_unalerted_comms)} unalerted communications.")

        # Sample the data
        df_sample = df_unalerted_comms.sample(n=size) if size > 0 else pd.DataFrame()

        # Replace "+" symbol in content IDs with ASCII code %2B
        df_sample['id'] = df_sample['id'].str.replace('+', '%2B', regex=True)

        # Retrieve content for each sampled communication
        comms_content = []
        for c_id in df_sample['id']:
            comm_data = get_comms_by_id(session, c_id)
            content_text = comm_data.get('content', {}).get('text', '')
            comms_content.append(content_text)
            print(f"Retrieved content for comm ID {c_id}")

        df_sample['content'] = comms_content

    # Save output to an Excel file
    if save_file and not df_sample.empty:
        filename = "output_sample.xlsx"
        df_sample.to_excel(filename, index=False)
        print(f"Sampled data saved to {filename}")
    elif df_sample.empty:
        print("No unalerted communications found. No file generated.")

if __name__ == "__main__":
    main(save_file=True)